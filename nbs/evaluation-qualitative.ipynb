{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2896bb4",
   "metadata": {},
   "source": [
    "### Lemmatisierer Evaluierung - qualitativ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc601129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4d86a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = glob.glob(\"lemmata/*.csv\")\n",
    "corpora = [f.split(\"baseline-\")[1].replace(\".csv\", \"\") for f in FILES if \"baseline\" in f]\n",
    "algos = [f.split(\"lemmata-\")[1].split('-')[0] for f in FILES if \"-ud-hdt\" in f]\n",
    "data = []\n",
    "df_all = pd.DataFrame(columns=(['corpus', 'token', 'tag', 'tag_STTS', 'lemma']+algos[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "873ef2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'lemmata/lemmata-stanza-empirist-web-norm.csv' empirist-web-norm not lemmatized by stanza\n",
      "\n",
      "[Errno 2] No such file or directory: 'lemmata/lemmata-stanza-empirist-web.csv' empirist-web not lemmatized by stanza\n",
      "\n",
      "[Errno 2] No such file or directory: 'lemmata/lemmata-germalemma-nosta-d-tuebadz-norm.csv' nosta-d-tuebadz-norm not lemmatized by germalemma\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for corpus in corpora:\n",
    "    df = pd.read_csv(f\"lemmata/lemmata-baseline-{corpus}.csv\", encoding=\"utf-8\")#encoding_errors='ignore'\n",
    "    df['corpus'] = corpus\n",
    "    df.rename(columns = {'lemma_gold': 'lemma'}, inplace = True)\n",
    "    df = df.drop(['lemma_pred'], axis=1)\n",
    "    df = df[['corpus', 'token', 'tag', 'tag_STTS', 'lemma']]\n",
    "    for a in algos[1:]:  # ignore baseline\n",
    "        try:\n",
    "            df[a] = pd.read_csv(f\"lemmata/lemmata-{a}-{corpus}.csv\", encoding=\"utf-8\", encoding_errors='ignore')[\"lemma_pred\"]\n",
    "        except Exception as e:  # corpus not lemmatized by algorithm\n",
    "            print(e, f\"{corpus} not lemmatized by {a}\\n\")\n",
    "    data.append(df)\n",
    "    #df.to_csv(f\"lemmata/overall/{corpus}.csv\", encoding=\"utf-8\")\n",
    "    df_all = df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79b19786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"lemmata/overview/all.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ae250c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['empirist-cmc-blog-norm',\n",
       "  'empirist-cmc-blog',\n",
       "  'empirist-cmc-chat-prof-norm',\n",
       "  'empirist-cmc-chat-prof',\n",
       "  'empirist-cmc-chat-social-norm',\n",
       "  'empirist-cmc-chat-social',\n",
       "  'empirist-cmc-twitter-norm',\n",
       "  'empirist-cmc-twitter',\n",
       "  'empirist-cmc-whatsapp-norm',\n",
       "  'empirist-cmc-whatsapp',\n",
       "  'empirist-cmc-wiki-norm',\n",
       "  'empirist-cmc-wiki',\n",
       "  'empirist-web-norm',\n",
       "  'empirist-web',\n",
       "  'germanc',\n",
       "  'nosta-d-anselm-norm',\n",
       "  'nosta-d-anselm-orig',\n",
       "  'nosta-d-bematac-norm',\n",
       "  'nosta-d-bematac-orig',\n",
       "  'nosta-d-falko-norm',\n",
       "  'nosta-d-falko-orig',\n",
       "  'nosta-d-kafka-norm',\n",
       "  'nosta-d-kafka-orig',\n",
       "  'nosta-d-tuebadz-norm',\n",
       "  'nosta-d-tuebadz-orig',\n",
       "  'nosta-d-unicum-norm',\n",
       "  'nosta-d-unicum-orig',\n",
       "  'rub2019-novelette',\n",
       "  'rub2019-sermononline',\n",
       "  'rub2019-subtitles',\n",
       "  'rub2019-ted',\n",
       "  'rub2019-wikipedia',\n",
       "  'tgermacorp',\n",
       "  'ud-gsd',\n",
       "  'ud-hdt',\n",
       "  'ud-pud'],\n",
       " ['baseline',\n",
       "  'germalemma',\n",
       "  'simplemma',\n",
       "  'spacy2',\n",
       "  'spacy3',\n",
       "  'spacy33+',\n",
       "  'stanza',\n",
       "  'trankit',\n",
       "  'treetagger'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora, algos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
